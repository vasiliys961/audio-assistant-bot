import sounddevice as sd
from scipy.io.wavfile import write
import whisper
from openai import OpenAI
import os
import time
from datetime import datetime

class AudioAssistant:
    def __init__(self, openai_api_key=None):
        self.api_key = openai_api_key
        self.fs = 44100  # —á–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏
        self.client = None
        
        if openai_api_key:
            self.client = OpenAI(
                base_url="https://openrouter.ai/api/v1",
                api_key=openai_api_key
            )
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∞—É–¥–∏–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤
        print("–î–æ—Å—Ç—É–ø–Ω—ã–µ –∞—É–¥–∏–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞:")
        devices = sd.query_devices()
        for i, device in enumerate(devices):
            if device['max_input_channels'] > 0:
                print(f"  {i}: {device['name']} (–≤—Ö–æ–¥: {device['max_input_channels']} –∫–∞–Ω–∞–ª–æ–≤)")
        
    def record_audio(self, seconds=30, filename=None):
        """–ó–∞–ø–∏—Å—å –∞—É–¥–∏–æ"""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"conversation_{timestamp}.wav"
            
        print(f"–ù–∞—á–∏–Ω–∞–µ—Ç—Å—è –∑–∞–ø–∏—Å—å –Ω–∞ {seconds} —Å–µ–∫—É–Ω–¥...")
        print("–ì–æ–≤–æ—Ä–∏—Ç–µ —Å–µ–π—á–∞—Å!")
        
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ 1 –∫–∞–Ω–∞–ª (mono) –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –æ—à–∏–±–æ–∫
            recording = sd.rec(int(seconds * self.fs), samplerate=self.fs, channels=1, dtype='int16')
            sd.wait()
            write(filename, self.fs, recording)
            print(f"–ì–æ—Ç–æ–≤–æ! –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –∫–∞–∫ {filename}")
            return filename
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏: {e}")
            # –ü–æ–ø—Ä–æ–±—É–µ–º —Å –¥—Ä—É–≥–∏–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
            try:
                print("–ü–æ–ø—ã—Ç–∫–∞ –∑–∞–ø–∏—Å–∏ —Å –¥—Ä—É–≥–∏–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏...")
                recording = sd.rec(int(seconds * self.fs), samplerate=self.fs, channels=1, dtype='float32')
                sd.wait()
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ int16
                recording = (recording * 32767).astype('int16')
                write(filename, self.fs, recording)
                print(f"–ì–æ—Ç–æ–≤–æ! –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –∫–∞–∫ {filename}")
                return filename
            except Exception as e2:
                raise Exception(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–∞—Ç—å –∞—É–¥–∏–æ: {e2}")
    
    def load_audio_file(self, filename):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞"""
        if os.path.exists(filename):
            print(f"–ó–∞–≥—Ä—É–∂–µ–Ω —Ñ–∞–π–ª: {filename}")
            return filename
        else:
            print(f"–§–∞–π–ª {filename} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
            return None
    
    def transcribe_audio(self, filename, model_size="small", language="ru"):
        """–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –∞—É–¥–∏–æ"""
        print("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ Whisper...")
        model = whisper.load_model(model_size)
        
        print("–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –∞—É–¥–∏–æ...")
        result = model.transcribe(filename, language=language)
        transcribed_text = result["text"]
        
        print("–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
        return transcribed_text
    
    def create_summary(self, text, max_points=5):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑—é–º–µ —Å –ø–æ–º–æ—â—å—é GPT"""
        if not self.client:
            print("API –∫–ª—é—á –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω!")
            return None
            
        print("–°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑—é–º–µ...")
        
        prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ä–∞–∑–≥–æ–≤–æ—Ä –∏ —Å–æ–∑–¥–∞–π –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ —Å –æ—Å–Ω–æ–≤–Ω—ã–º–∏ –º–æ–º–µ–Ω—Ç–∞–º–∏.
        –í—ã–¥–µ–ª–∏ –Ω–µ –±–æ–ª–µ–µ {max_points} –∫–ª—é—á–µ–≤—ã—Ö –ø—É–Ω–∫—Ç–æ–≤.
        –†–∞–∑–≥–æ–≤–æ—Ä –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:
        {text}"""
        
        try:
            response = self.client.chat.completions.create(
                model="openai/gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "–¢—ã –ø–æ–º–æ—â–Ω–∏–∫, —Å–æ–∑–¥–∞—é—â–∏–π –∫—Ä–∞—Ç–∫–∏–µ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–∑—é–º–µ —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤. –í—ã–¥–µ–ª—è–π –æ—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=500,
                temperature=0.3
            )
            
            summary = response.choices[0].message.content
            print("–†–µ–∑—é–º–µ —Å–æ–∑–¥–∞–Ω–æ!")
            return summary
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Ä–µ–∑—é–º–µ: {e}")
            return None
    
    def save_results(self, text, summary, base_filename):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Ñ–∞–π–ª—ã"""
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
        transcript_file = base_filename.replace('.wav', '_transcript.txt')
        with open(transcript_file, 'w', encoding='utf-8') as f:
            f.write("–¢–ï–ö–°–¢ –†–ê–ó–ì–û–í–û–†–ê:\n")
            f.write("=" * 50 + "\n")
            f.write(text)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—é–º–µ
        if summary:
            summary_file = base_filename.replace('.wav', '_summary.txt')
            with open(summary_file, 'w', encoding='utf-8') as f:
                f.write("–†–ï–ó–Æ–ú–ï –†–ê–ó–ì–û–í–û–†–ê:\n")
                f.write("=" * 50 + "\n")
                f.write(summary)
            
            print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª—ã:")
            print(f"  - –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç: {transcript_file}")
            print(f"  - –†–µ–∑—é–º–µ: {summary_file}")
        else:
            print(f"–¢–µ–∫—Å—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {transcript_file}")

def main():
    print("üéôÔ∏è  –ê—É–¥–∏–æ –ø–æ–º–æ—â–Ω–∏–∫ - –ó–∞–ø–∏—Å—å, —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –∏ —Ä–µ–∑—é–º–µ")
    print("=" * 50)
    
    # –í–∞—à API –∫–ª—é—á –æ—Ç OpenRouter
    API_KEY = "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"
    
    assistant = AudioAssistant(openai_api_key=API_KEY)
    
    while True:
        print("\n–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:")
        print("1. –ó–∞–ø–∏—Å–∞—Ç—å –Ω–æ–≤—ã–π —Ä–∞–∑–≥–æ–≤–æ—Ä")
        print("2. –û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∞—É–¥–∏–æ —Ñ–∞–π–ª")
        print("3. –í—ã—Ö–æ–¥")
        
        choice = input("\n–í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä –¥–µ–π—Å—Ç–≤–∏—è (1-3): ").strip()
        
        if choice == "1":
            # –ó–∞–ø–∏—Å—å –Ω–æ–≤–æ–≥–æ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
            try:
                duration = int(input("–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∑–∞–ø–∏—Å–∏ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 30): ") or "30")
                filename = assistant.record_audio(seconds=duration)
                
                # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è
                text = assistant.transcribe_audio(filename)
                print("\n–†–ê–°–®–ò–§–†–û–í–ö–ê:")
                print("-" * 30)
                print(text[:500] + "..." if len(text) > 500 else text)
                
                # –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑—é–º–µ
                summary = assistant.create_summary(text)
                if summary:
                    print("\n–†–ï–ó–Æ–ú–ï:")
                    print("-" * 30)
                    print(summary)
                
                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                assistant.save_results(text, summary, filename)
                
            except ValueError:
                print("–û—à–∏–±–∫–∞: –≤–≤–µ–¥–∏—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ —á–∏—Å–ª–æ —Å–µ–∫—É–Ω–¥")
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏: {e}")
        
        elif choice == "2":
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —Ñ–∞–π–ª–∞
            filename = input("–í–≤–µ–¥–∏—Ç–µ –∏–º—è –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞: ").strip()
            if not filename.endswith(('.wav', '.mp3', '.m4a', '.flac')):
                filename += '.wav'
            
            audio_file = assistant.load_audio_file(filename)
            if audio_file:
                try:
                    # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è
                    text = assistant.transcribe_audio(audio_file)
                    print("\n–†–ê–°–®–ò–§–†–û–í–ö–ê:")
                    print("-" * 30)
                    print(text[:500] + "..." if len(text) > 500 else text)
                    
                    # –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑—é–º–µ
                    summary = assistant.create_summary(text)
                    if summary:
                        print("\n–†–ï–ó–Æ–ú–ï:")
                        print("-" * 30)
                        print(summary)
                    
                    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                    assistant.save_results(text, summary, audio_file)
                    
                except Exception as e:
                    print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {e}")
        
        elif choice == "3":
            print("–î–æ —Å–≤–∏–¥–∞–Ω–∏—è! üëã")
            break
        
        else:
            print("–ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.")

if __name__ == "__main__":
    main()
